# MySQL是怎样运行的

## 1  初识MySQL

- **MySQL是客户端/服务器架构**。

###  1.1 服务器处理客户端请求

<img src="./PIC/MySQL查询请求执行过程.png" style="zoom: 80%;" />

 1. 连接管理
    客户端可以采用TCP/IP，管道或者共享内存等几种方式来建立连接。每当一个客户端进程进来服务端都会创建一个线程与客户端交互，连接断开不会销毁线程，放入线程池。服务端的最大连接数为151。
  
 2. 解析与优化

    解析与优化包括查询缓存、语法解析和查询优化。

    - 查询缓存
    MySQL服务器会把刚刚处理过的查询请求和结果缓存起来。如果下一次有一样的查询过来，直接查询缓存。但是两个查询有任何字符集上的不同，都会导致缓存不命中。缓存也会存在缓存失效的时候，只要该表的结构或者数据被修改，相关的查询缓存就会失效。

	- 语法解析
	MySQL对发送的请求进行分析，提取信息，相当于一个编译过程。
	
	- 查询优化
	MySQL的优化程序会对我们的语句做一些优化，生成一堆计划，提高执行效率。
	
3. 存储引擎
	MySQL服务器把数据的存储和提取操作都封装到一个名为存储引擎的模块里面。服务器和存储引擎层的交互一般是以记录为单位。
### 1.2 常用存储引擎
![](./PIC/MySQL常用存储引擎.png)
![](./PIC/存储引擎支持功能.png)

## 2. 启动选项和系统变量

- 启动选项：可以调整服务器启动后的一些行为，它可以在命令行中指定，也可以将他们写入配置文件。
- 系统变量：是服务器维护的一些变量，影响着服务器的行为。它的作用范围为全局范围和会话范围。
- 状态变量：显示服务器程序的运行状态。

## 3. 字符集和比较规则

### 3.1 简介
- 编码：将字符映射成二进制数据的过程叫作编码。
- 解码：将二进制数据映射成字符的过程叫解码。

- 字符集：是某个字符范围的编码规则。
- 比较规则：比较两个字符大小的规则。

| 字符集名称 | Maxlen(代表最多可以用Maxlen表示一个字符) |
| ---------- | ---------------------------------------- |
| ascii      | 1                                        |
| gb2312     | 2                                        |
| gbk        | 2                                        |
| utf8       | 3                                        |
| utf8mb4    | 4                                        |
| latin1     | 1                                        |

###  3.2 MySQL有4个级别的字符集和比较规则

1. 服务器级别
	- `character_set_server`表示服务器级别的字符集，`collation_server`表示服务器级别的比较规则

	2. 数据库级别
	- 创建和修改数据库时可以指定字符集和比较规则
	
	CREATE|ALTER DATABASE 数据库名
	[[DEFAULT] CHARACTER SET 字符集名称]
	[[DEFAULT] COLLATE 比较规则名称];
	
	- `character_set_database`表示当前数据库字符集，`collation_database`表示当前数据库的比较规则。这两个系统变量仅仅用来读取。
	- 如果没有指定字符集和比较规则，则和服务器的系统变量一致
	
	3. 表级别
	4. 列级别
	**二者方式与数据库级别类似**
	
	- 仅仅修改字符集，则比较规则也会变成修改后的字符集的默认比较规则；
	- 只修改比较规则，则字符集将变成修改后的比较规则对应的字符集。
	
	### 发送请求到接受相应字符集的转换
	- 客户端发送的请求字节序是采用哪种字符集进行编码的？
		取决于操作系统当前使用的字符集。
	- 服务器接受到的请求字节序列后采用的编码方式？
		取决于系统变量`character_set_client`。
	- 服务器在运行处理过程中采用的编码方式？
		取决于系统变量`character_set_connection`
	- 服务器返回字节序列的采用的编码方式？
		取决于系统变量`character_set_results`。
	- 客户端接受到相应字节序之后，如何显示给用户？
		取决于操作系统当前使用的字符集。
	- 一般建立连接的过程中，会把`character_set_client`和`character_set_connection`和`character_set_results`设置成为与客户端操作系统采用的字符集。



## 4. InnoDB的记录存储结构

### 4.1 InnoDB简介
InnoDB是一个将表中的数据存储到磁盘上的存储引擎，正真的数据处理过程发生在内存中。InnoDB是将数据划分为多个页，以页作为磁盘和内存之间交互的基本单位。一般页的大小为16KB。一次做少从磁盘读取16KB的数据或者把16KB的数据刷新到磁盘。

- 以记录(一行)为单位向表中插入数据，InnoDB有四种不同类型的行格式，分别是`COMPACT`，`REDUNDANT`，`DYNAMIC`，`COMPRESSED`。

### 4.2 COMPACT 行格式

![](./PIC/COMPACT行格式.png)

- 一条完整的记录由记录的额外信息和记录的真实数据两大部分。
- 记录的额外信息：包括变长字段长度列表，NULL值列表，记录头信息。
- 1. 变成字段长度列表：
	- 变长字段中存储的字节数不确定，因此要存储这些真实数据所占的字节数。一个记录里面变长字段占用的存储空间包括两部分，真正的数据内容和该数据占用的字节数。
	- 在`COMPACT`行格式里面，所有变长字段的真实数据占用的字节数放在记录的开头，形成一个变长字段长度列表，变长字段的真实数据占用的字节数按照**列的逆序存放**！
	- 仅仅存储非NULL列的内容长度。
- 2. NULL值列表
	- `COMPACT`格式会把一条记录中值为NULL的列统一管理，放到NULL值列表里面。
	- 首先统计允许存储NULL值的列表有哪些（先排除主键，以及NOT NULL修饰的）
	- 若没有允许存储NULL的列，则不存在；否则将每个允许存储NULL的列对应一个二进制位，按照**列的逆序存放**。二进制位的值为1，则代表该列为NULL；为0代表部位NULL。
	- MySQL中规定NULL值列表必须为整数个字节位表示。
<img src="./PIC/NULL值列表.png" style="zoom:67%;" />

- 3. 记录头信息
	- 由固定5字节组成
	![](./PIC/记录头信息.png)
	<img src="./PIC/记录头信息二进制位.png" style="zoom:70%;" />
	- `record_type`为 0，1，2，3分别代表普通用户记录，目录项记录，Infimum记录和Supremum记录。
	
 - 4. 记录的真实数据
	- MySQL会为每个记录添加一些默认列。
	![](./PIC/默认添加列.png)
	没有主键则会添加第一行
	- 溢出列：对于`COMPACT`和`REDUNDANT`行格式来说，对于占用空间很大的列，在记录的真实数据只会存储该列的一部分，而把剩余的数据分散到其他页中，然后在记录的真实数据用20字节存储指向这些页的地址。
	![](./PIC/溢出页.png)

### 4.3 DYNAMIC格式和COMPRESSED格式
- 它们不会再记录真实数据处记录溢出列的前768字节，只记录溢出页的地址。
- `COMPRESSED`行格式和`DYNAMIC`的区别是前者采用了头部压缩算法对页面进行压缩，以节省空间。
![](./PIC/DYNAMIC和COMPRESSED格式.png)



## 5. InnoDB数据页结构

- InnoDB 为了不同的目的而设计了许多种不同类型的页 ，比如存放表空间头部信息的页，存放 Insert Buffer信息的页，存放 INODE 信息的页，存放 undo 日志信息的页等。
- 存放记录那种类型的页，也叫索引页（INDEX）。

### 5.1 数据页结构
<img src="./PIC/InnoDB数据页结构.png" style="zoom:50%;" />

| 名称             | 中文名                     | 占用空间大小 | 简单描述           |
| ---------------- | -------------------------- | ------------ | ------------------ |
| File Header      | 文件头部                   | 38字节       | 页的一些通用信息   |
| Page Header      | 页面头部                   | 56字节       | 数据页的专有信息   |
| Infimum+Supremum | 页面中的最小记录和最大记录 | 26字节       | 两个虚拟记录       |
| User Records     | 用户记录                   | 不确定       | 用户存储记录内容   |
| Free Page        | 空闲空间                   | 不确定       | 页中尚未使用的空间 |
| Page Directory   | 页目录                     | 不确定       | 页中某些记录的位置 |
| File Trailer     | 文件尾部                   | 8字节        | 校验页是否完整     |

### 5.2 记录在页中的存储

- 每插入一条记录时，都会从Free Space部分申请一个记录的大小空间，划分到User Records部分。当Free Space用完之后，就要申请新的页。
![](./PIC/记录插入过程.png)

							头部信息描述
| 名称   | 大小 | 描述     |
| ------ | ---- | -------- |
| 预留位1 | 1    | 没有使用 |
| 预留位2       | 1     | 没有使用         |
| deleted_flag       |   1   |  标记该记录是否被删除        |
| min_rec_flag       |   1   |  B+树中每层非叶子节点中的最小的目录下记录都会添加此标记        |
| n_owned | 4 | 一个页面的记录被分为若干这组，每个组中有一个记录是"带头大哥"，其余的记录都是小弟。大哥记录的n_owned值代表此组中所有记录的条数，小弟的n_owned的值都为0 |
| heap_no | 13 | 表示当前记录再页面堆的相对位置。 |
| record_type | 3 | 表示当前记录的类型，0表示普通记录，1表示b+树非叶节点的目录项记录，2表示Infimum记录，3表示Supremum记录 |
| next_record | 16 | 下一条记录的相对位置 |



- 举例说明
<img src="./PIC/记录存储.png" style="zoom:80%;" />
`deleted_flag`:值位0代表没被删除，1代表被删除。被删除的记录还在磁盘上，原因是避免移除后的重新排列。被删除的记录形成一个垃圾链表，是一个可重用空间
`heap_no`:记录一条一条紧密排列的结构叫做堆，一条记录在堆里面的相对位置叫做`heap_no`。InnoDB添加了两个虚拟记录，Infimum记录代表页面中的最小记录，`heap_no`为0，Supremum代表页面中的最大记录，`heap_no`为1。比较记录的大小就是比较主键的大小。
`next_record`:表示从当前记录的真实数据到下一条记录的真实数据的距离。下一条记录 指得并不是按照我们插入顺序的下一条记录，而是按照主键值由小到大的顺序的下一条记录。
<img src="./PIC/最大最小记录.png" style="zoom: 80%;" />
由图可知，记录按照主键从小大到大顺序形成了一个单向链表。Supremum的next_record为0，表示它之后无记录。
<img src="./PIC/删除记录.png" style="zoom: 80%;" />
删掉一条记录2，记录2并没有从存储空间移除，而是deleted_flag为1,next_record为0.
第一条的next_record记录指向了第三条记录。



### 5.3 页目录(Page Directory)

记录在页中是按照主键从小到大顺序串联成一个单向链表，根据主键查找某一记录时，若记录很多很多，沿着单链表顺序查找显然不行。因此InnoDB设计了页目录。制作过程如下：
- 所有正常记录（包括Infimum和Supremum记录，但不包括已经移除到垃圾链表的记录）划分为几个组。
- 每个组的最后一条记录选为带头大哥，它的n_owned属性记录组里有多少记录
- 每个组带头大哥在页面中的地址偏移量单独提取出来，存储到页目录。页目录里面的这些地址偏移叫做槽，每个槽两个字节。页目录由多个槽组成。
- <img src="./PIC/页目录.png" style="zoom: 80%;" />
- 规定：`Infimum`记录所在的分组只能有1条记录，也就是他自己。`Supremum`记录拥有的记录可以在1-8之间。其余分组的记录条数是在4-8之间。

查找过程：二分搜索，先找出要找主键所在的槽，因此就可以确定分组，然后通过next_record再遍历该分组即可。

### 5.4 页面头部（Page Header）
**专门针对数据页**
记录存储在数据页中的记录的状态信息，比如数据页记录了多少条记录，还未使用的最小地址空间在页面的地址偏移量，页目录里面存储了多少个槽，Page_Free：被删除记录组成的链表的头节点。

### 5.5 文件头部（File Header）
通用于各个类型的页，各种页都是以其作为第一个组成部分，比如：该页的编号，该页的上一页和下一页，LSN。

### 5.6 文件尾部（File Trailer）
该部分由8字节组成，分为两部分。
- 前四字节代表页的校验和，于File Header里面的校验和相对应。
- 后四字节代表页面最后被修改时对应的LSN的后四字节，如果页首和页尾的校验和以及LSN不同，则说明刷新期间出了问题。

## 6. B+树索引

InnoDB的各个数据页可以组成一个双向链表,而每个数据页中的记录会按照主键从小到大的顺序组成一个单向链表。每个数据页都会为存储在里面的记录生成一个页目录，通过主键查找某条记录的时候可以在页目录中用二分法快速定位对应的槽，在遍历槽里面的记录即可。

页和记录的关系如下：
<img src="./PIC/页和记录的关系.png" style="zoom: 80%;" />

当记录很多很多，需要用到很多数据页来存储，首先要里面索引，定位到记录所在的页，然后在所在页里面查找相应的记录。

###  6.1 InnoDB中的索引方案

目录项记录：与用户记录长得很像，目录项中的两个列是主键(其他索引)和页号。
目录项记录和用户记录的区别：

- 目录下记录的record_type值是1，普通用户记录为0；
- 目录下记录只记录主键和页号两列，普通用户记录记录的列是用户自己定义的，还包括InnoDB的隐藏列；
- min_rec_flag属性，只有目录项记录的属性才可以能为1，用户记录为0。

B+树：无论存放用户记录数据页还是存放目录下记录的数据页，都放到B+树这个数据结构，正真的用户记录放到B+树的最底层节点上即叶子节点，其余用来存放目录项记录的节点成为内节点，最上面的节点成为根节点，如图所示：

<img src="./PIC/B+树.png" style="zoom: 80%;" />

下一个数据页中的用户记录的主键值必须大于上一页用户记录的主键值，因此在对页中记录进行增删改查的时候可能会发生页分裂。
给页建立目录项的时候存放的是主键和页号的键值对，其中主键取某一页里面的最小值。
这样根据主键值查找记录的时候，我们最多查找的页就是b+树的高度，每个页都可以利用二分法快速搜寻。

**聚簇索引**

- B+树本身就是一个目录or索引，特点如下：
- 使用记录主键值的大小进行记录和页的排序：
	- 页（包括叶子节点和内节点）内的记录按照主键的大小排成一个单向链表，页内记录被划分为若干个组，每个组中主键值的最大的记录在页内的偏移量会被存放在页目录中（Supremum记录比 任何用户记录都大），在页目录里面通过二分法快速定位。
	- 各个存放用户记录的页有合适根据页中用户记录的主键大小顺序排成一个双向链表。
	- 存放目录项记录的页分为不同层级，在同一层级的页也是根据页目录项记录的主键大小排成一个双向链表
	
- B+树叶子节点存储的是完整的用户记录。

  具备以上两个特点的B+树称为聚簇索引，InnoDB 存储引擎会自动的为我们创建聚簇索引。在 InnoDB 存储引擎中， 聚簇索引就是数据的存储方式（所有的用户记录都存储在了 叶子节点 ），也就是所谓的索引即数据，数据即索引。

**二级索引**

聚簇索引搜索条件是主键才能发挥作用，用其他列的大小作为数据页，页中记录的排序规则，建立B+树，称为二级索引。
- 其中B+树的叶子节点存放的不是完整的用户记录，而是其他列+主键。
- 目录项记录也不是主键+页号的搭配，而是其他列+主键+页号的搭配。
- 找到相应的主键后还要执行回表操作，才能得到完整的数据记录。

**联合索引**
同时为多个列建立索引，比如B+树按照c2和c3列进行排序，先把各个记录和页按照c2列进行排序，在c2列相同的情况下，再按照c3列进行排序。

**InnoDB B+树注意事项**

- 每当为某个表创建一个B+树索引（聚簇索引不是人为创建的，默认就有）的时候，都会为这个索引创建一个根节点页面。最开始表中没有数据的时候，每个B+树索引对应的 根节点中既没有用户记录，也没有目录项记录。
- 随后向表中插入用户记录时，先把用户记录存储到这个根节点中。
- 当根节点中的可用空间用完时继续插入记录，此时会将根节点中的所有记录复制到一个新分配的页，比如页a 中，然后对这个新页进行页分裂的操作，得到另一个新页，比如页b。这时新插入的记录根据键值（也就是聚簇索引中的主键值，二级索引中对应的索引列的值）的大小就会被分配到页a 或者 页b中，而根节点便升级为存储目录项记录的页。
- 一个B+树索引的根节点自创建之之后它的页号就不会再改变，这样我们对某个表建立一个索引，它的根节点的页号就不会再该改变，而是记录在某个地方，然后凡是 InnoDB 存储引擎需要用到这个索引的时候，都会从那个固定的地方取出 根节点 的页号，从而来访问这个索引。这个存储某个索引的根节点在哪个页面中的信息就是传说中的数据字典中的一项信息。
- 一个数据页至少存放两条记录。

### 6.2 MyISAM的索引方案

我们知道 InnoDB 中索引即数据，也就是聚簇索引的那棵B+树的叶子节点中已经把所有完整的用户记录都包含了，而MyISAM的索引方案虽然也使用树形结构，但是却将索引和数据分开存储：
- 将表中的记录按照记录的插入顺序单独存储在一个文件中，称之为数据文件 。这个文件并不划分为若干个数据页，有多少记录就往这个文件中塞多少记录就成了。我们可以通过行号而快速访问到一条记录。
<img src="./PIC/MyISAM数据页.png" style="zoom: 80%;" />
- 使用MyISAM存储引擎的表会把索引信息另外存储到一个称为索引文件的另一个文件中。 MyISAM 会单独为表的主键创建一个索引，只不过在索引的叶子节点中存储的不是完整的用户记录，而是主键值+行号的组合。也就是先通过索引找到对应的行号，再通过行号去找对应的记录！
- 这一点和 InnoDB 是完全不相同的，在 InnoDB 存储引擎中，我们只需要根据主键值对聚簇索引进行一次查 找就能找到对应的记录，而在 MyISAM 中却需要进行一次回表操作，意味着 MyISAM 中建立的索引相当于全 部都是二级索引 ！
- MyISAM的行格式有定长记录格式（Static）、变长记录格式（Dynamic）、压缩记录格式（Compressed）。上边用到的index_demo表采用定长记录格式，也就是一条记录占用存储空间的大小是固定的，这样就可以轻松算出某条记录在数据文件中的地址偏移量。但是变长记录格式就不行了，MyIS AM会直接在索引叶子节点处存储该条记录在数据文件中的地址偏移量。通过这个可以看出，MyISAM 的回表操作是十分快速的，因为是拿着地址偏移量直接到文件中取数据的，反观InnoDB是通过获取主键之后再去聚簇索引里边儿找记录，虽然说也不慢，但还是比不上直接用地址去访问。

## 7. 应用B+树索引(简单带过)

- B+树索引在时间和空间上都有代价，不要瞎建立索引。
- 索引可以用于减少扫描记录的数量，也可以用于分组和排序。
- 在使用索引来减少需要扫描的记录的数量时，应该先找到使用该索引执行查询时对应的扫描区间和形成该扫描区间的边界条件，然后就可以扫描各个扫描区间的记录。
- 创建和使用索引的注意事项：
  - 只为用于搜索、排序和分组的列创建索引；
  - 当列中不重复的个数在总记录的条数占比很大时，才为列建立索引；
  - 索引列的类型尽量小；
  - 可以只为索引列前缀创建索引，减少索引占用的存储空间；
  - 尽量使用覆盖索引进行查询，避免回表操作带来的性能损耗；
  - 为了尽可能地少让聚簇索引发生页面分裂地情况，建议让主键拥有自动增长属性；
  - 定位并删除表中地冗余和重复索引；
  - 让索引列以列名地方式出现在搜索条件中。


## 8. MySQL的数据目录
像InnoDB、MyISAM这样的存储引起都是把数据存储到文件系统上。
MySQL服务器程序在启动时会到数据目录中加载数据，运行过程产生的数据也会存储到数据目录中，系统变量datadir显示了这个路径。

- 数据库：
	每个数据库对应着数据目录下的一个子目录，子目录中包含一个名为dp.opt的文件，包含了一些数据库的属性，比如数据库的字符集和比较规则等。

- 表：
	对于InnoDB存储引擎，如果使用系统表空间，那么只会在该表所在数据库的对应子目录下面创建一个名为“表名.frm”的文件，表中的数据存储在系统表空间。
	如果使用独立表空间存储表中的数据，那么会在该表所在数据库对应子目录创建一个“表名.frm”的文件，还会创建一个名为“表名.ibd”文件，数据存储在后者，前者代表表的结构。
	
	对于MyISAM存储引擎来说，会在该表所在的数据库对应的子目录下创建三个文件。
	- 表名.frm：表示表的结构文件；
	- 表名.MY：表示表的数据文件；
	- 表名.MYI：表示表的索引文件。
	
  
  
  
  
  
## 9. MySQL的数据目录
  ### 	9.1 回忆旧知识
  **常见页面类型**
  <img src="./PIC/常见页面类型.png" style="zoom: 80%;" />

  - 我们的聚簇索引(也就是完整的表数据)以及其他的二级索引都是以B+树的形式保存到表空间,B+树叶子节点就是数据页

  **页面的通用**

  <img src="./PIC/页面通用部分.png" style="zoom: 80%;" />

- File Header：记录页面的一些通用信息。

- File Trailer：校验页是否完整，保证页面在内存刷新到磁盘后的内容是相同的。
  <img src="./PIC/File header组成.png" style="zoom: 80%;" />
	- 表空间的每个页对应一个页号，基于页号可以快速定位指定页面；
	- 某些类型的页可以组成链表，链表中相邻的页面的页号可以不连续，File_Page_Next和File_Page_Prev存取了下一个和上一个的页号，这两个字段主要用于Index页。
	- 每个页的类型由File_Page_Type表示。

###  9.2. 独立表空间结构
- 区：对于16kb的页来说，连续的64个页面就是一个区，一个区默认1MB；
- 组：每256个区为一个组；
<img src="./PIC/每个组的头几个页面.png" style="zoom: 80%;" />
- 第一个组的最开始三个页面时固定的：
	- FSP_HDR：这个页面的类型用来登记表空间的一些属性以及本组所有的区的属性，一个表空间只有一个；
	- IBUF_BITMAP：用来存储Change Buffer的信息；
	- INODE：存储了许多INODE ENTRY的数据结构；
- 其余各组的最开始两个页面的也是固定的：
	- XDES：用来登记本组256个区的属性。
	- IBUF_BITMAP：略。


- 段：向表里面插入一条记录，本质是向该表的聚簇索引以及所有的二级索引代表的B+树的节点插入数据，B+树每一层相邻的页构成一个双向链表，两个页之间可能会相隔很远，为了使得链表相邻页的物理位置也相邻，引入段；一个区就是物理位置连续的64个页，当表数据很大时，为索引分配空间就以区为单位。
    - 一个索引产生两个段：一个存放叶子节点的区的集合和存放非叶子节点的区的集合 。段是以区为单位申请存储空间的。
    
    - 刚开始向表里面插入数据的时候，段是从某个碎片区以单个页面为单位来分配存储空间；
    
- 当某个段已经占用了32个碎片区的时候，就会以完整的区为单位来分配存储空间。
  
    - 段的概念：一些零散的页面以及完整的区的集合。
    
      
    
- 区的分类
    | 状态名    | 含义               |
    | --------- | ------------------ |
    | FREE      | 空闲的区           |
    | FREE_FRAG | 有空闲页面的碎片区 |
    | FULL_FRAG | 无空闲页面的碎片区 |
    | FSEG      | 附属某个段的区     |

    - 前三个状态的区直接附属于表空间，而后一个附属于段。

      
    
- XDES Entry：每个区都对应着一个XDES Entry结构，对应了区的一些属性。
<img src="./PIC/XDES.png" style="zoom: 80%;" />
	 - 每一个段都有一个唯一的编号，用ID表示，此处的 Segment ID 字段表示就是该区所在的段。当然前提是该区已经被分配给某个段了，不然的话该字段的值没啥意义。
	 - List Node：这个部分可以将若干个 XDES Entry 结构串联成一个链表；
	 - State：表示区的状态，与前文所述一致；
	 - Page State Bitmap：记录某个页是否空闲。

- XDES Entry链表：当段中的数据较少时，先检查表空间是否有状态为FREE FRAG的区，也就是找有空闲空间的碎片区，找到了，就从该区取一些零碎的页把数据插进去；否则就是到表空间申请一个状态为FREE的区，变为 FREE  FRAG，然后从里面取数据，之后不同的段使用零碎页的时候都会从该区中取，直到该区中没有空闲空间，然后该区的状态就变成了FULL_FRAG 。如何知道表空间的区的状态，可以利用LIST NODE 指针。
	- 把状态为 FREE 的区对应的 XDES Entry 结构通过 List Node 来连接成一个链表，这个链表我们就称之为 FREE 链表。
	- 把状态为 FREE_FRAG 的区对应的 XDES Entry 结构通过 List Node 来连接成一个链表，这个链表我们就称之为 FREE_FRAG 链表。
	- 把状态为 FULL_FRAG 的区对应的 XDES Entry 结构通过 List Node 来连接成一个链表，这个链表我们就称之为 FULL_FRAG 链表。
	
- 这样每当我们想找一个 FREE_FRAG 状态的区时，就直接把 FREE_FRAG 链表的头节点拿出来，从这个节点中取一些零碎的页来插入数据，当这个节点对应的区用完时，就修改一下这个节点的 State 字段的值，然后从 FREE_FRAG 链表中移到 FULL_FRAG 链表中。同理，如果 FREE_FRAG 链表中一个节点都没有，那么就直接从 FREE 链表中取一个节点移动到 FREE_FRAG 链表的状态，并修改该节点的 STATE 字段值为FREE_FRAG ，然后从这个节点对应的区中获取零碎的页就好了。

- 当段中数据已经占满了32个零散的页后，就直接申请完整的区来插入数据了。

- 上述的三个链表时直属于表空间的区的链表，存储与FSP HDR的 FILE SPACE HEADER部分。

- 每个段的区对应的XDES Entry结构也建立链表：
	- FREE 链表：同一个段中，所有页面都是空闲的区对应的 XDES Entry 结构会被加入到这个链表。注意和直属于表空间的 FREE 链表区别开了，此处的 FREE 链表是附属于某个段的。
	
	- NOT_FULL 链表：同一个段中，仍有空闲空间的区对应的 XDES Entry 结构会被加入到这个链表。

	- FULL 链表：同一个段中，已经没有空闲空间的区对应的 XDES Entry 结构会被加入到这个链表。
	
	  
	
- 链表基节点：为了找到上述的链表而设计List Base Node 的结构，这个结构中包含了链表的头节点和尾节点的指针以及这个链表中包含了多少节点的信息。
<img src="./PIC/List  Base Node.png" style="zoom: 80%;" />
  
- 总结：表空间由若干个区组成的，每个区都对应一个XDES Entry结构，直属于表空间的区对应的XDES Entry结构可以分成 FREE、FREE FRAG和FULL FRAG这三个链表；每个段拥有若干个区，每个段的区对应的XDES Entry可以构成FREE、NOT FULL、FULL三个链表。每个链表对应一个LIST BASE NODE结构，记录了链表头尾节点的位置和该链表的节点数。

    

- 段的结构：每个段都定义了一个INODE Entry结构，记录段的属性。
  <img src="./PIC/段的结构.png" style="zoom: 80%;" />

  - Segment ID：这个INODE Entry结构对应的段的编号。
  - NOT FULL N USED：在NOT FULL链表里面使用了多少个页面。
  - 3个LIST BASE NODE：如前文所述。
  - Magic Number：标记这个INODE ENTRY是否初始化。
  - Fragment Array Entry：记录零散页的页号。
  
  


- FSP_HDR：第一个组的第一个页面，也是表空间的第一个页面，记录了表空间的整体属性和第一个组内256个区对应的XDES Entry结构。

  

<img src="./PIC/FSP_HDR.png" style="zoom: 80%;" />

| 名称              | 中文名         | 大小（字节） | 描述                                                         |
| ----------------- | -------------- | ------------ | ------------------------------------------------------------ |
| File Header       | 文件头部       | 38           | 页的一些通用信息                                             |
| File Space Header | 表空间头部     | 112          | 表空间的一些整体描述<br />属于表空间的区的三种链表的信息存于此 |
| XDES Entry        | 区描述信息     | 10240        | 存储本组256个区对应的属性信息，一个40字节                    |
| Empty Space       | 尚未使用的空间 |              |                                                              |
| File Trailer      | 文件尾部       | 8            | 校验页是否完整                                               |
- File Space Header结构描述

| 名称                                    | 大小 | 描述                               |
| --------------------------------------- | ---- | ---------------------------------- |
| Space ID                                | 4    | 表空间的ID                         |
| NOT Used                                | 4    | 未被使用，可以忽略                 |
| Size                                    | 4    | 当前表空间拥有的页面数             |
| Free Limit                              | 4    |                                    |
| Space Flags                             | 4    | 表空间的一些占用存储空间较小的属性 |
| FRAG_N_USED                             | 4    | FREE_FRAGS链表中已经使用的页面数   |
| List Base Node for FREE List            | 16   | FREE 链表的基节点                  |
| List Base Node for FREE_FRAG List       | 16   | FREE_FRAG 链表的基节点             |
| List Base Node for FULL_FRAG List       | 16   | FULL_FRAG 链表的基节点             |
| Next  Unused Segment ID                 | 8    | 下一个未使用的段的ID               |
| List Base Node for SEG_INODES_FULL LIST | 16   |                                    |
| List Base Node for SEG_INODES_FREE LIST | 16   |                                    |

- 每个段对应的 INODE Entry 结构会集中存放到一个类型位 INODE 的页中，如果表空间中的段特别多，则会有 多个 INODE Entry 结构，可能一个页放不下，这些 INODE 类型的页会组成两种列表： SEG_INODES_FULL 链表，该链表中的 INODE 类型的页面都已经被 INODE Entry 结构填充满了，没空闲 空间存放额外的 INODE Entry 了。 SEG_INODES_FREE 链表，该链表中的 INODE 类型的页面都已经仍有空闲空间来存放 INODE Entry 结构。



- XDES类型：第一个分组之后的每个分组第一个页面的类型叫XDES，记录这个分组的XDES  Entry，与FSP_HDR。

- IBUF_BITMAP：记录了一些Change  Buffer的东西。

- INODE类型：为了存储INODE Entry结构的页

	<img src="./PIC/INODE.png" style="zoom: 80%;" />

	- File Header：页面的一些通用信息；Empty Space：页结构的填充，无用；File Trailer：校验页是否完整。
	- List Node for INODE Page List：存储上一个INODE页面和下一个INODE页面的指针。
	- INODE Entry：段的信息，192字节，一个INODE页可以存储85个这样的结构

- Segment Header：一个索引产生两个段，一个叶子节点的段和非叶子节点段，每个段对应一个INODE Entry，如何知道哪个段对应哪个INODE Entry结构呢？------ 数据页的Page Header部分！

  | 名称              | 大小    | 描述                                       |
  | ----------------- | ------- | ------------------------------------------ |
  | PAGE_BTR_SEG_LEAF | 10 字节 | B+树叶子段的头部信息，仅在B+树的根页定义   |
  | PAGE_BTR_SEG_TOP  | 10 字节 | B+树非叶子段的头部信息，仅在B+树的根页定义 |

  - PAGE_BTR_SEG_LEAG对应一个Segment Header结构，记录叶子节点段对应的INODE Entry的地址对应表空间哪个页面以及偏移量
  - PAGE_BTR_SEG_TOP对应一个Segment Header结构，记录非叶子节点段对应的INODE Entry的地址对应表空间哪个页面以及偏移量

### 9.3   系统表空间

- 系统表空间的整体结构

  <img src="./PIC/系统表空间.png" style="zoom: 80%;" />

- 数据字典：为了更好的管理用户数据而不得已引入的一些额外数据，也成为元数据。比如：该表的聚簇索引 和所有二级索引对应的根页面是哪个表空间的哪个页面，某个表属于哪个表空间，表里边有多少列，表对应的每一个列的类型是什么 该表有多少索引，每个索引对应哪几个字段，该索引对应的根页面在哪个表空间的哪个页面， 该表有哪些外键，外键对应哪个表的哪些列 某个表空间对应文件系统上文件路径是什么？

- 用来描述元数据的表，其中INNODB_SYS_INDEXES，INNODB_SYS_TABLES， INNODB_SYS_FIELDS，INNODB_SYS_COLUMNS 表十分重要，成为系统基本表。系统空间的第7个页面记录了数据字典的头部信息。



## 10. 单表的访问方法

​	MySQL Server对一条查询语句进行语法解析之后，就会交给优化器进行优化，生成一个所谓的执行计划。这个执行计划表明了应该使用哪些索引进行查询、表之间的连接顺序是啥样的等等。

### 10.1 访问方法

#### const

​	把通过主键或者唯一二级索引列来定位一条记录的访问方法定义为const，意思是常数级别的，代价可以忽略不计，const方法仅仅在主键或者唯一二级索引和常数进行等值比较才有效。
 <img src="./PIC/二级索引查找.png" style="zoom: 80%;" />

 - 二级索引进行查找还需要进行回表操作

#### ref
普通的二级索引与常数进行等值比较，由于普通二级索引列值不唯一性，所以会产生一个扫描区间，代价取决于区间的记录条数。每找到一条二级索引记录，就会立即执行回表操作。

- 对于可以存储NULL值的二级索引列，最多只能用ref方法而非const；	

#### ref_or_null

​	不仅想找出二级索引列的值等于常数的记录，还想把该列值为null的记录全部找出来，方法为ref_or_null。

#### range

​	使用索引进行查询的时候，若对应扫描区间为若干个单点扫描或范围扫描，方法叫做range。

#### index

​	扫描全部二级索引记录的访问方法称为index方法。

#### ALL

​	扫描全部的聚簇索引。



### 10.2 二级索引+回表

例如一下查询：
```MySQL
select * from single_table where key1 = 'abc' and key2 > 1000;
```

查询优化器会识别这两个搜索条件，看哪个区间对应的成本更少。假设我们采取key1索引来执行查询，那么步骤如下：

- 先通过key1对应的B+树定位到扫描区间的第一条二级索引记录；
- 根据主键进行回表操作，得到完整的用户记录，再检测是否满足key2大于1000；
- 再根据此纪录的next_record找到下一条二级索引记录，重复上述步骤，直至不满足key1=abc。

### 10.3 索引合并

​	MySQL把使用多个索引来完成一次查询的方法称为索引合并。

 - Intersection索引合并：就是指对从不同索引中扫描到的记录的id值取交集，只为这些id进行回表操作。并且每个使用到的索引都是二级索引的话，要求每个索引得到的二级索引记录的记录都是按照主键值排序的，否则不能使用Intersection 索引合并。
```
select * from single_table where key1 = 'a' and key3 = 'b';
```
同时使用key1和key3执行查询，从二者形成的扫描区间区交集（主键值相同），在这些交集里面进行回表操作。

- union 索引合并：同时对key1和key3进行查询，将区间得到的所有id进行去重后，得到的id集合进行回表操作，即取并集。要求每个索引得到的二级索引记录的记录都是按照主键值排序的，否则不能使用Intersection 索引合并。
```
select * from single_table where key1 = 'a' OR key3 = 'b';
```

- sort-union 索引合并：先根据key1条件获取二级索引记录,并将二级索引记录的值按照主键排序，再根据key3的条件获取相应的二级索引记录，并按照主键进行排序，然后再执行union操作。

```
select * from single_table where key1 < 'a' OR key3 > 'z';
```



## 11. 连接的原理

### 11.1 连接的本质

#### 11.1.1 连接的本质

​	连接的本质就是把各表中的记录都取出来依次进行匹配，并把匹配后的结果发给客户端。这样的结果积称为笛卡尔积，如图所示：

<img src="./PIC/连接的本质.png" style="zoom: 100%;" />

#### 11.1.2 连接过程简介

<img src="./PIC/连接过程.png" style="zoom: 80%;" />

- 确定一个驱动表，第一个要查询的表；
- 从驱动表中获取到每一条符合要求的记录，到被驱动表查找匹配的记录。
- 驱动表进要访问一次，被驱动表需要访问多次。

#### 11.1.3 内连接和外连接

- 内连接：对于内连接的两个表，若驱动表中的记录在被驱动表中找不到匹配的记录，则该记录不会加入到最后的结果集。
 - 外连接：对于内连接的两个表，若驱动表中的记录在被驱动表中找不到匹配的记录，则该记录会加入到最后的结果集。
   - 左外连接：选择左侧的表为驱动表；
   - 右外连接：选择右侧的表为驱动表。
- where过滤条件：不论是内连接还是外连接，凡是不符合 WHERE 子句中的过滤条件的记录都不会被加入最后的结果集。
- on过滤条件：对于外连接的驱动表的记录来说，如果无法在被驱动表中找到匹配 ON 子句中的过滤条件的记录，那么该记录仍然会被加入到结果集中，对应的被驱动表记录的各个字段使用 NULL 值填充；内连接中的WHERE子句和ON子句是等价的

```
左外连接：
	SELECT * FROM t1 LEFT [OUTER] JOIN t2 ON 连接条件 [WHERE普通过滤条件];
右外连接：
	SELECT * FROM t1 RIGHT [OUTER] JOIN t2 ON 连接条件 [WHERE普通过滤条件];
内连接语法：
	SELECT * FROM t1 [INNER | CROSS] JOIN t2 [ON 连接条件] [WHERE 普通过滤条件]
	内连接和外连接的根本区别就是在驱动表中的记录不符合 ON 子句中的连接条件时不会把该记录加入到最后的结果集
```

- 对于内连接来说，驱动表和被驱动是可以互换的，并不会影响最后的结果集；而对于外连接来说，由于驱动表中的记录即使在被驱动表中找不到符合 ON 子句连接条件的记录，所以此时驱动表和被驱动表的关系就很重要了，也就是说左外连接和右外连接的驱动表和被驱动表不能轻易互换。

### 11.2 连接的原理

- 嵌套循环连接：种驱动表只访问一次，但被驱动表却可能被多次访问，访问次数取决于 对驱动表执行单表查询后的结果集中的记录条数的连接执行方式称之为 嵌套循环连接 。
- 使用索引加快连接速度：更换驱动表和被驱动表的位置，利用索引减少被驱动表的查找速度。并且使用正真用到的列作为查询列表，说不定可以减少回表的操作。



## 12. 基于成本的优化

- I/O成本：我们的表经常使用的MyISAM、InnoDB存储引擎都是将数据和索引存储到磁盘里面。当查询表中的记录的时候，先要把数据或者索引加载到内存里面，然后再进行操作，这个从磁盘到内存的损耗叫做I/O成本。
- CPU成本：读取记录以及检测记录是否满足对应的要求、对结果集进行排序等等这些操作损耗的时间称为CPU成本。
- 对于InnoDB存储引擎来说，读取一个页面的默认成本是1.0，读取以及检测一条记录是否符合搜索条件的默认成本是0.2。


### 12.1 单表查询
**单表查询，优化器生成执行计划的步骤如下：**

- 根据搜索条件，找出所有可能使用的索引；
- 计算全表扫描的代价；根据show table status就可以查看表的统计信息，得到记录条数和data_length，进而求出页面数
- 计算使用不同索引执行查询的代价；
  - 对于二级索引+回表的查找方式，先要统计扫描区间的数量；再统计需要回表的记录数；如果区间最左侧到最右边的记录不大于10个页面，那么直接遍历，访问每个页面的Page Header里面记录该页面有多少条记录的属性，否则沿着区间从左往右读取10个页面，计算记录的平均数，乘以页面的页数（通过父节点的页面记录数可以求得）。
- 对比各种执行方案的代价，选择成本最低的方案。

### 12.2 基于统计数据的成本计算

- 通过直接访问索引所对应的B+树来计算某个扫描区间对应的索引记录条数称为index dive

- 如果扫描区间太多太多，大于等于200，则不会使用index dive，通过统计数据来计算


### 12.3 连接查询的成本

#### 12.3.1 条件过滤

MySQL连接查询采用的是嵌套循环连接算法，驱动表访问一次，被驱动表访问多次，因此对于两表连接查询来说，它的查询成本由两部分组成：

- 单次查询驱动表的成本；
- 多次查询被驱动表的成本（取决于多次驱动表里面有多少条记录，扇出）

条件过滤：采用某些规则预测驱动表的扇出值。如果使用全表扫描的方法执行单表查询，那么计算驱动表扇出的时候需要猜测满足全部搜索条件的记录有多少条；如果使用索引执行单表查询，计算驱动表删除的时候需要猜测满足形成索引扫描区间的搜索条件之外，还满足其他搜索条件的记录有多少条。

连接查询的成本公式 = 单词访问驱动表的成本+驱动表扇出值x单次访问被驱动表的成本
对于左外和右外来说，他的驱动表是固定的，所以只需要分别为两表选择成本最低的访问方法即可。

对于内连接来说，驱动表和被驱动表的位置可以互换，因此要考虑两个方面：
- 不同的表作为驱动表，最终查询成本可能不同，需要考虑表的连接顺序；
- 然后分别为驱动表和被驱动表选择成本最低的方法。



## 13. InnoDB是如何收集数据的

InnoDB以表为单位来收集和存储统计数据，分为永久性地存储统计数据和非永久性地存储统计数据。

- 永久性地存储统计数据：统计数据存储在磁盘上面，服务器重启数据还在；
- 非永久性地存储统计数据：统计数据存储在内存中





## 14. 基于规则的优化


### 14.1 化简条件

用户写的表达式可能无法高效的执行，MySQL优化器会对我们语句进行重写：

- 移除不必要的括号；
- 常量传递，有时候某个列和某个常量等值匹配，把那个列替换为常量；

```mysql
a = 5 and b > a  替换为  a = 5 and b > 5; 
```

- 移除没用的条件，对于一些明显永远为true和为false的表达式，优化器会将他们移除
- 表达式计算，如果表达式只包含常量的时候，先计算出来；注意，**最好让索引列以单独的形式出现在搜索条件表达式当中**。
- 如果查询语句没有出现sum，max这样的聚集函数或者group  by子句，优化器会把HAVING 子句和 WHERE子句合并， 

- 常量表检测，MySQL认为这两类查询语句特别快，化器在分析一个查询语句时，先首先执行常量表查询，然后把查 询中涉及到该表的条件全部替换成常数，最后再分析其余表的查询成本

  ```mysql
  SELECT * FROM table1 INNER JOIN table2
  ON table1.column1 = table2.column2 
  WHERE table1.primary_key = 1;
  
  SELECT table1表记录的各个字段的常量值, table2.* FROM table1 INNER JOIN table2 
  ON table1表column1列的常量值 = table2.column2;
  
  
  ```

  

  - 查询表中一条记录都没有或者只有一条记录；
  - 使用主键等值匹配或者唯一索引列等值匹配作为搜索条件来查询某个表
  
  
### 14.2 外连接消除
- 外连接消除：**外连接和内连接的本质区别就是：对于外连接的驱动表的记录来说，如果无法在被驱动表中找到 匹配ON子句中的过滤条件的记录，那么该记录仍然会被加入到结果集中，对应的被驱动表记录的各个字段使用 NULL值填充；而内连接的驱动表的记录如果无法在被驱动表中找到匹配ON子句中的过滤条件的记录，那么该记录会被舍弃**；凡是不符合WHERE子句中条件的记录都不会参与连接。只要我们在搜索条件中指定关于被驱动表相关列的值不为 NULL ，那么外连接中在被驱动表中找不到符合 ON 子句条件的驱动表记 录也就被排除出最后的结果集了，也就是说：在这种情况下：外连接和内连接也就没有什么区别了！指定的 WHERE 子句中包含被驱动表中的列不为 NULL 值的条件称之为 空值拒绝 （英文名： reject-NULL ）。在被驱动表的WHERE子句符合空值拒绝的条件后，外连接和内连接可以相互转 换。这种转换带来的好处就是查询优化器可以通过评估表的不同连接顺序的成本，选出成本最低的那种连接顺序 来执行查询。

### 14.3 子查询 

#### 14.3.1 子查询语法

```mysql
1. select子句中  select (select m1 from t1 limit 1);
2. from子句中   select m,n from (select xxxx); from后面的子查询也叫派生表
3. where 或者on 子句的表达式中  select * from t1 where m1 in (select xxxx);
```

1. 按照返回的结果集区分子查询

   - 标量子查询：那些只返回单一子查询的查询称为标量子查询；
   - 行子查询：返回一条记录的子查询，不过这个记录需要包含多个列；
   - 列子查询：查询出一个列的数据，不过这个列需要包含多条记录；
   - 表子查询：子查询的结果包含多条记录，又包含多个列；

2. 按与外层关系来区分子查询

   - 不相关子查询：如果子查询可以单独运行出结果，不依赖外层查询的值；
   - 相关子查询：如果子查询的执行需要依赖于外出查询的值。

3. 子查询在bool表达式中的使用

   - 使用比较操作符作为bool表达式的操作符  操作数 比较操作符   子查询，这里的子查询只能是标量子查询或者行子查询
   - NOT/IN/ANY/ALL 子查询
     - 操作数   IN/NOT IN   子查询；判断某个操作数是否在子查询结果集组成的集合中；
     - 操作数  比较操作符   ANY/SOME   子查询；这个布尔表达式的意思是只要子查询结果集中存在某个值和给定的操作数做 comparison_operator 比较 结果为 TRUE ，那么整个表达式的结果就为 TRUE ，否则整个表达式的结果就为 FALSE 。
     - 操作数  比较操作符   ALL  子查询；这个布尔表达式的意思是子查询结果集中所有的值和给定的操作数做 comparison_operator 比较结果 为 TRUE ，那么整个表达式的结果就为 TRUE ，否则整个表达式的结果就为 FALSE 。
     - exits 子查询：有时候仅仅需要判断子查询的结果集中是否有记录，而不在乎它的记录具体是啥。  例如 select * from  t1 where exists (select xxx)；

4. 子查询的语法注意事项
- 子查询必需用括号括起来；
- select子句里面的子查询必需是标量子查询；
- 需要得到标量子查询或者行子查询，但又不能保证子查询的结果集只有一条记录时，需要用limit 1语句限制数量；
- 对于NOT IN ANY ALL等等子查询，子查询不允许有LIMIT语句。


#### 14.3.2 子查询执行过程

1. 标量子查询、行子查询的执行方式：

   - select子句中的子查询必须是标量子查询；
   - 子查询使用比较操作符和某个操作数组成一个bool表达式，这样的子查询必须是标量子查询或者行子查询；

   对于查询语句，其执行方式如下

   ```mysql
   SELECT * FROM s1 
    WHERE key1 = (SELECT common_field FROM s2 WHERE key3 = 'a' LIMIT 1);
    
   ```

   - 先单独执行 (SELECT common_field FROM s2 WHERE key3 = 'a' LIMIT 1) 这个子查询；
   - 然后在将上一步子查询得到的结果当作外层查询的参数再执行外层查询 SELECT * FROM s1 WHERE key1 =

   也就是说，对于包含不相关的标量子查询或者行子查询的查询语句来说，MySQL会分别独立的执行外层查询和子查询，就当作两个单表查询就好了。

   对于对于相关的标量子查询或者行子查询来说，比如下边这个查询：

   ```mysql
   SELECT * FROM s1 WHERE 
    key1 = (SELECT common_field FROM s2 WHERE s1.key3 = s2.key3 LIMIT 1);
   ```

   - 先从外层查询中获取一条记录，本例中也就是先从 s1 表中获取一条记录。
   - 然后从上一步骤中获取的那条记录中找出子查询中涉及到的值，本例中就是从 s1 表中获取的那条记录中找 出 s1.key3 列的值，然后执行子查询。
   - 最后根据子查询的查询结果来检测外层查询 WHERE 子句的条件是否成立，如果成立，就把外层查询的那条记 录加入到结果集，否则就丢弃。
   - 再次执行第一步，获取第二条外层查询中的记录，依次类推

2. IN 子查询优化
   ```mysql
   SELECT * FROM s1 
    WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = 'a')
   ```

- 对于不相关的in子查询，如果子查询的记录特别特别多，那么mysql不会将子查询的结果集当作外层查询的参数，而是将结果写入一个临时表：

   - 该临时表的列就是子查询结果集的列；
   - 写入临时表的记录会被去重
   - 如果子查询的结果不会太大，就会为它基于内存使用的MEMORY存储引擎建立临时表，并且为该表建立哈希索引；
   - 如果查询结果非常大，那么就会把子查询的结果集保存到一个临时表保存到磁盘，这个过程叫做**物化**。
   
- 物化表转连接

   假设物化表叫做materialized_table ，该物化表存储的子查询结果 集的列为 m_val ，那么这个查询其实可以从下边两种角度来看待：

   - 从表 s1 的角度来看待，整个查询的意思其实是：对于 s1 表中的每条记录来说，如果该记录的 key1 列的值在子查询对应的物化表中，则该记录会被加入最终的结果集。
   - 从子查询物化表的角度来看待，整个查询的意思其实是：对于子查询物化表的每个值来说，如果能在 s1 表中找到对应的 key1 列的值与该值相等的记录，那么就把这些记录加入到最终的结果集。
   - 也就是说其实上边的查询就相当于表 s1 和子查询物化表 materialized_table 进行内连接：

   ```mysql
   SELECT s1.* FROM s1 INNER JOIN materialized_table ON key1 = m_val;
   ```

   优化查询器会评估不同的连接顺序需要的成本是多少，选择不同的表作为驱动表进行选择。

- 子查询转为半连接

```mysql
SELECT * FROM s1 
 WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = 'a')
```

​	我们可以把这个查询理解为：对于s1里面的某条记录，如果能在s2表找到一条或者多条记录，这些记录的 common_field 的值等于 s1 表记录的 key1 列的值， 那么该条 s1 表的记录就会被加入到最终的结果集。可以分三种情况讨论：

	情况1：对于S1表中的某条记录来说，S2表找不到任何记录满足条件，那么该记录不会加入结果集
	情况2：对于S1表中的某条记录来说，S2表中有且只有一条记录满足条件，那么该记录会被加入结果集
	情况3：对于S1表中的某条记录来说，S2表中有多条记录满足满足条件，那么该记录可能会被加入结果集多次

​	半连接：将 s1 表和 s2 表进行半连接的意思就是：对于 s1 表的某 条记录来说，我们只关心在 s2 表中是否存在与之匹配的记录是否存在，而不关心具体有多少条记录与之匹配， 最终的结果集中只保留 s1 表的记录。实现方法有：

 - Table pullout：当子查询的查询列表处只有主键或者唯一索引列时，可以直接把子查询中的表 上拉 到外层查询的 FROM 子句 中，并把子查询中的搜索条件合并到外层查询的搜索条件中

   ```mysql
    SELECT * FROM s1 
    WHERE key2 IN (SELECT key2 FROM s2 WHERE key3 = 'a');
    
    SELECT s1.* FROM s1 INNER JOIN s2 
    ON s1.key2 = s2.key2 
    WHERE s2.key3 = 'a';
   因为子查询的查询列表只有主键或者唯一二级索引的时候，就可以将子查询转为连接查询
   ```

 - DuplicateWeedout execution strategy （重复值消除）

   ```MYSQL
   SELECT * FROM s1 
   WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = 'a');
   对于这个查询来说，转换为半连接查询之后，S1的某条记录在S2表里面可能有多条匹配的记录，这个记录可能被增加多次，为了消除重复，建立了一个临时表 这种使用临时表消除 semi-join 结果集中的重复值的方式称之为 DuplicateWeedout 。
   ```

   - LooseScan execution strategy （松散索引扫描）

     ```mysql
     在子查询中，对于 s2 表的访问可以使用到 key1 列的索引，而恰好子查询的查询列表处就是 key1 列，这样
     在将该查询转换为半连接查询后，如果将 s2 作为驱动表执行查询的话，那么执行过程就是这样：
     如图所示，在 s2 表的 idx_key1 索引中，值为 'aa' 的二级索引记录一共有3条，那么只需要取第一条的值
     到 s1 表中查找 s1.key3 = 'aa' 的记录，如果能在 s1 表中找到对应的记录，那么就把对应的记录加入到结
     果集。依此类推，其他值相同的二级索引记录，也只需要取第一条记录的值到 s1 表中找匹配的记录，这种
     虽然是扫描索引，但只取值相同的记录的第一条去做匹配操作的方式称之为 松散索引扫描 。
     ```

     <img src="./PIC/松散扫描.png" style="zoom: 100%;" />

   - Semi-join Materialization execution strategy （半连接物化）

    - FirstMatch execution strategy （首次匹配）

3. 半连接的适用条件

- 该子查询必须是和 IN 语句组成的布尔表达式，并且在外层查询的 WHERE 或者 ON 子句中出现。 

- 外层查询也可以有其他的搜索条件，只不过和 IN 子查询的搜索条件必须使用 AND 连接起来。 

- 该子查询必须是一个单一的查询，不能是由若干查询由 UNION 连接起来的形式。 

- 该子查询不能包含 GROUP BY 或者 HAVING 语句或者聚集函数。

### 14.3 总结

MySQL对in的子查询进行了很多优化。如果in子查询符合转换为半连接的条件，那么查询优化器会把子查询转换为半连接，然后考虑上述五种半连接查询策略中哪个成本最低，取执行成本最低的执行。

如果in子查询不符合半连接条件，那么查询优化器会从以下两种策略选择一种成本更低的进行子查询：

- 先将子查询物化，然后再执行查询；
- 执行in到exists的转换，有时候可能能用上索引



## 17. InoDB的Buffer Pool

概念：为了缓存磁盘中的页，InnoDB存储引擎在MySQL服务器启动的时候向操作系统内存申请了一片连续的内存，称为buffer pool。这样每次访问一页中的一条记录，就会把完整的页中的数

### 17.1 Buffer pool的内部组成
Buffer pool对应一片连续的内存区域，被划分为若干个页面，默认16KB。这些页叫做缓冲页。每个缓冲页都创建一个控制信息，包括该页的表空间编号、页号、缓存页在buffer pool的地址等等，把这些控制信息都保存在一个页里面叫控制块，控制块和缓冲页一一对应。

<img src="./PIC/buffer pool.png" style="zoom: 100%;" />


### 17.2 free链表的管理
我们最好在某个地方记录一下Buffer Pool中哪些缓存页是可用的，把所有空闲缓冲页对应的控制块作为节点放到一个链表里面，称为空闲链表。

<img src="./PIC/buffer 空闲链表.png" style="zoom: 100%;" />

为了管理free链表，特地为这个链表定义了一个基节点，里面包含链表头节点地址，尾节点地址和数量等信息。链表的基节点占用的内存空间 并不包含在为 Buffer Pool 申请的一大片连续内存空间之内，而是单独申请的一块内存空间

为了快速定位某个页是否被加载到buffer pool，可以使用表空间+页号作为key，缓冲页地址作为value来建立哈希表进行快速定位。

### 17.3 flush链表的管理

在buffer pool中，被修改的页称为脏页。脏页不是立即刷新的，而是加入到flash链表里面，待某个时刻刷新到磁盘里面。

<img src="./PIC/flash链表.png" style="zoom: 100%;" />

### 17.4 LRU链表的管理

为了应对缓冲区不够的窘境，就需要淘汰调最近很少使用的缓冲页，我们使用LRU链表来管理，当我们使用了某个缓冲页的时候，就把该换缓冲页移动到LRU链表的首部，当buffer pool的空闲页用完了时候，就淘汰掉LRU尾部的页即可。

- 预读：所谓预读，就是InnoDB认为执行当前请求的时候，可能会在后面读取某些页面，于是就预先把这些页面读取的buffer pool之中，根据出发方式的不同，预读可以分为线性预读和随机预读。
- 线性预读：如果顺序访问了某个区（ extent ）的页面超过这个系统变量的值，就会触发一次异步读取下一个区中全部的页面到 Buffer Pool 的请求，注意异步读取意味着从磁盘中加载这些被预读的页面并不会影响到当前工作线程的正常执行。
- 随机预读：如果 Buffer Pool 中已经缓存了某个区的13个连续的页面，不论这些页面是不是顺序读取的，都会触发一次异步读取本区中所有其的页面到 Buffer Pool的请求。
- 这些预读的页不如果都放到buffer pool的首部，而导致buffer pool尾部的一些页被淘汰，会降低命中率
- 加载到 Buffer Pool 中的页不一定被用到。如果非常多的使用频率偏低的页被同时加载到 Buffer Pool 时，可能会把那些使用频率非常高的页从Buffer Pool 中淘汰掉。这两点都造成buffer pool的命中率降低。

<img src="./PIC/LRU链表.png" style="zoom: 100%;" />

LRU链表分为young区和old区。首次加载到buffer pool里面的页会放到old区域的头部，在innodb_blocks_time间隔时间访问该页的时候，不会把他移动到young区的头部。在buffer pool没有可用空闲缓冲页的时候，首先淘汰old区域的一些页。

- 针对预读：针对预读的页面可能不进行后续访情况的优化
设计 InnoDB 的大叔规定，当磁盘上的某个页面在初次加载到Buffer Pool中的某个缓存页时，该缓存页对应的控制块会被放到old区域的头部。这样针对预读到 Buffer Pool 却不进行后续访问的页面就会被逐渐从old 区域逐出，而不会影响 young 区域中被使用比较频繁的缓存页。
- 针对全表扫描：在对某个处在 old 区域的缓存页进行第一次访问时就在它对应的控制块中
记录下来这个访问时间，如果后续的访问时间与第一次访问的时间在某个时间间隔内，那么该页面就不会被从old区域移动到young区域的头部，否则将它移动到young区域的头部。

## 18. 事务简介

事务：为了把现实世界的业务场景映射到数据库里面，需要事务，它是一种机制、一个操作序列，包含了一组数据库操作命令。事务把所有的命令作为一个整体一起向系统提交或撤销操作请求，即这一组数据库命令要么都执行，要么都不执行，因此事务是一个不可分割的工作逻辑单元。

事务的四大特性：

- 原子性：事务是一个完整的操作。事务的各元素是不可分的（原子的）。事务中的所有元素必须作为一个整体提交或回滚。如果事务中的任何元素失败，则整个事务将失败。要么全做，要么全部不做。
- 隔离性：其他状态转换不会影响到本次状态转换。数据进行修改的所有并发事务是彼此隔离的，这表明事务必须是独立的，它不应以任何方式依赖于或影响其他事务。修改数据的事务可以在另一个使用相同数据的事务开始之前访问这些数据，或者在另一个使用相同数据的事务结束之后访问这些数据。
- 一致性：数据库世界是现实世界的一个映射，现实世界的约束，数据库也需要满足。当事务完成时，数据必须处于一致状态。也就是说，在事务开始之前，数据库中存储的数据处于一致状态。在正在进行的事务中. 数据可能处于不一致的状态，如数据可能有部分被修改。然而，当事务成功完成时，数据必须再次回到已知的一致状态。通过事务对数据所做的修改不能损坏数据，或者说事务不能使数据存储处于不稳定的状态。
- 持久性：意味着本次转换对应的数据库操作所做的修改的数据都应该在磁盘上面保存下来。



事务的状态：

- 活动的：事务对应的数据库操作真正执行的过程。
- 部分提交的：当事务中的最后一个操作执行完成的时候，但由于操作都在内存中执行，所造成的影响没有刷新到磁盘，我们说事务处于部分提交的状态。
- 失败的：当事务处于活动的状态或者部分提交的状态，可能遇到了某些错误，而无法继续执行或者认为终止了当前事务的执行，就说数据处于失败的状态。
- 终止的：如果事务执行了半截而变为失败的，就需要撤销失败事务对当前数据库造成的影响。我们把这个撤销的过程称之为回滚 。当回滚操作执行完毕时，也就是数据库恢复到了执行事 务之前的状态，我们就说该事务处在了中止的 状态。
- 一个处在部分提交的 状态的事务将修改过的数据都同步到磁盘上之后，我们就可以说该事务处在了 提交 的 状态。

<img src="./PIC/事务的状态.png" style="zoom: 100%;" />

保存点：就是在事务对应的数据语句中打几个点，我们可以调用rollback语句指定回滚到哪个点。

```mysql
SQL语句
SAVE 保存点名称
rollback to  保存点名称
```



## 19. redo日志

我们只是想让已经提交了的事务对数据库中数据所做的修改永久生效，即使后来 系统崩溃，在重启后也能把这种修改恢复出来。所以我们其实没有必要在每次事务提交时就把该事务在内存中修 改过的全部页面刷新到磁盘，只需要把修改了哪些东西记录一下就好

redo日志：因为在系统崩溃而重启时需要记录修改的内容，按照上述内容记录的步骤重新更新数据数据页，所以上述内容就叫做redo日志。相较于事务提交的时候把所有修改过的内存中的页面提交到磁盘，只将该事务执行过程中产生的redo日志刷新到磁盘，有如下好处：

- redo日志空间非常小，
- redo时顺序写入磁盘的，在执行事务的过程中，每执行一条语句，可能 产生若干redo日志，这些日志按照生成顺序写入磁盘，也就是顺序I/O；

### 19.1 redo日志的格式

 redo 日志本质上只是记录了一下事务对数据库做了哪些修改。

<img src="./PIC/redo日志的结构.png" style="zoom: 100%;" />

- type：这条redo日志的类型；
- space id：表空间
- page number：页号
- data：redo日志的具体内容

某个表没有显式定义主键，或者表也没有定义不允许存储NULL值的unique键，InnoDB会自动为表添加一个row_id隐藏列作为主键。服务器会在内存维护一个全局变量，每当向某个包含row_id隐藏列的表插入一条记录时，就会把这个全局变量的值作为新纪录的row_id列的值，并把全局变量+1。每当全局变量为256的倍数的时候，就会把他刷新到磁盘上面，存在于系统表空间页号为7的页面的MAX ROW ID属性里面。系统启动 会把该变量加载到内存并加上256；

当这个属性为256的倍数的时候，会在系统表空间7号页相应偏移量写入8字节的数据，这个写入操作实际在Buffer pool完成，需要把修改保存在redo日志里面，redo日志只需要记录在某个页面某个偏移量修改了几个字节的数据，修改后的具体内容即可这种日志称为物理日志。

- MLOG_1BYTE （ type 字段对应的十进制数字为 1 ）：表示在页面的某个偏移量处写入1个字节的 redo 日志 类型。
- MLOG_2BYTE （ type 字段对应的十进制数字为 2 ）：表示在页面的某个偏移量处写入2个字节的 redo 日志 类型。 
- MLOG_4BYTE （ type 字段对应的十进制数字为 4 ）：表示在页面的某个偏移量处写入4个字节的 redo 日志 类型。
-  MLOG_8BYTE （ type 字段对应的十进制数字为 8 ）：表示在页面的某个偏移量处写入8个字节的 redo 日志 类型。 
- MLOG_WRITE_STRING （ type 字段对应的十进制数字为 30 ）：表示在页面的某个偏移量处写入一串数据

负责的日志：包含物理日志和逻辑日志

### 19.2 Mini-Transaction
执行语句产生的redo日志被分割成若干个不可分割的组，比如：
- 更新MAX ROW ID属性时产生的redo日志为一组，不可分割；
- 向聚簇索引对应的B+树的页面中插入一条记录时产生的redo日志为一组，不可分割；
- 向二级索引对应的B+树页面插入一条记录时产生的redo日志为一组，不可分割；

在保证原子性操作的时候，必需以组来记录日志，恢复也是。

把对底层页面进行一次原子访问的过程称为一个Mini-Transaction 
一个事务可以包含若干条语句，每一条语句其实是由若干个 mtr 组成，每一个 mtr 又可以包含若干条 redo 日志
<img src="./PIC/MTR.png" style="zoom: 100%;" />



### 19.3 redo日志的写入过程

为了管理redo日志,把通过MTR产生的redo日志都放到了大小为512字节的页中,称为block.redo日志都是存储到占用496字节的log block body中,前面时一些管理信息
<img src="./PIC/redo block.png" style="zoom: 100%;" />



redo日志缓冲区：写入日志时也不能直接写到磁盘中，实际上在服务器启动时就向操作系统申请了一大片redo log buffer，这片内存空间被划分为若干个redo log block

<img src="./PIC/redo log buffer.png" style="zoom: 100%;" />

### 19.4 redo日志文件
MTR运行过程产生的一组redo日志在MTR结束时会被复制到log buffer中

#### 19.4.1 redo日志刷盘时机
- log buffer 空间不足时，设计 InnoDB 的大叔认为如果当前写入 log buffer 的
redo 日志量已经占满了 log buffer 总容量的大约一半左右，就需要把这些日志刷新到磁盘上。
- 事务提交的时候，在事务提交时可以不把修改过的 Buffer Pool 页面刷新到磁盘，但是为了保证持久性，必须要把修改这些页面对应的 redo 日志刷新到磁盘。
- 后台线程刷新
- 造成关闭服务器时
- 做checkpoint时

#### 19.4.2 redo日志文件组
<img src="./PIC/redo日志文件组.png" style="zoom: 100%;" />

循环写入日志文件组，日志文件的大小=组的大小✖个数

#### 19.4.3 redo日志文件格式

我们前边说过 log buffer 本质上是一片连续的内存空间，被划分成了若干个 512 字节大小的 block 。将logbuffer中的redo日志刷新到磁盘的本质就是把block的镜像写入日志文件中，所以 redo 日志文件其实也是由若干个 512 字节大小的block组成。redo 日志文件组中的每个文件大小都一样，格式也一样，都是由两部分组成：前2048个字节，也就是前4个block是用来存储一些管理信息的。从第2048字节往后是用来存储 log buffer 中的block镜像的。

所以我们前边所说的 循环 使用redo日志文件，其实是从每个日志文件的第2048个字节开始算,如图：

<img src="./PIC/日志文件组示意图.png" style="zoom: 100%;" />


### 19.5 Log Sequence Number

InnDB设计了一个名为lsn的全局变量，来记录总共写入的日志量，初始值为8704。如果某个MTR产生的一组日志量小，lsn的增长量就是redo日志占用的字节数，如果很大，lsn的增长量还得加上额外的log block header 和log block trailer。
每一组由MTR产生的redo日志都有唯一一个lsn的值与其对应；lsn越小，redo日志产生的越早，这个结论比较重要。

**flushed_to_disk_lsn**：

redo日志先是写入到log buffer里面然后再被刷新到磁盘的redo日志文件中，lsn表示当前系统写入的redo日志量，包括了写的log buffer里面没有刷新到磁盘的日志，InnoDB设计了一个全局变量，表示刷新到磁盘的redo日志量，名为flushed_to_disk_lsn。系统第一次启动时，该变量的值和初始的 lsn 值是相同的，都是 8704 。随着系统的运行， redo 日志被不断写入 log buffer ，但是并不会立即刷新到磁盘， lsn 的值就和 flushed_to_disk_lsn 的值拉开了差距

<img src="./PIC/flushed_to_disk_lsn.png" style="zoom: 100%;" />

综上所述，当有新的 redo 日志写入到 log buffer 时，首先 lsn 的值会增长，但 flushed_to_disk_lsn 不变， 随后随着不断有 log buffer 中的日志被刷新到磁盘上， flushed_to_disk_lsn 的值也跟着增长。如果两者的值 相同时，说明log buffer中的所有redo日志都已经刷新到磁盘中了。

**可以通过lsn的值求得日志文件组中的偏移量的对应关系**



**flush链表中的lsn**

一个MTR代表对底层页面的一次原子访问，在访问的过程中可能会产生一组不可分割的redo日志；在MTR结束的时候，会把这一组redo日志写入log buffer之中，此外，MTR结束的时候还需要把修改过的页加入到buffer pool的flush链表中。

当第一次修改某个页面的时候，就会把这个页面对应的控制块插入flush链表的头部，之后在修改，由于已经在flush链表，所以就不在插入了，flush链表中的脏页是按照页面的第一次修改的时间排序的。在这个过程中会在缓存页对应的控制块中记录两个关于页面何时修改的属 性： 

- oldest_modification ：第一次修改buffer pool中的某个缓冲页，就将修改该页面的MTR开始时对应的LSN值写入
- newest_modification ：每修改一次页面，都会将修改该页面的 mtr 结束时对应的 lsn 值写入这个属性。 也就是说该属性表示页面最近一次修改后对应的系统 lsn 值。



### 19.6  checkpoint

redo日志只是为了系统 奔溃后恢复脏页用的，如果对应的脏页已经刷新到了磁盘，也就是说即使现在系统奔溃，那么在重启后也用不着 使用redo日志恢复该页面了，所以该redo日志也就没有存在的必要了，那么它占用的磁盘空间就可以被后续的 redo日志所重用。也就是说：判断某些redo日志占用的磁盘空间是否可以覆盖的依据就是它对应的脏页是否已经 刷新到磁盘里

InnoDB维护一个全局变量 checkpoint_lsn，用来表示当前系统可以被覆盖的redo日志总量是多少，初始值也为8704。比如，当页面a被刷新到磁盘上面，所以可以进行一次checkpoint_lsn操作。我们把这个过程叫做执行一次checkpoint。

执行一次checkpoint的步骤：

- 计算当前系统可以被覆盖的redo日志对应的lsn值最大时多少

  redo 日志可以被覆盖，意味着它对应的脏页被刷到了磁盘，只要我们计算出当前系统中被最早修改的脏页 对应的 oldest_modification 值，那凡是在系统lsn值小于该节点的oldest_modification值时产生的redo日志 都是可以被覆盖掉的，我们就把该脏页的 oldest_modification 赋值给 checkpoint_lsn 。

- 将checkpoint_lsn与对应的redo日志文件组偏移量以及批次checkpoint的编号写到checkpoint1或者checkpoint2中

- InnoDB维护了一个目前系统做了多少次 checkpoint 的变量 checkpoint_no ，每做一次 checkpoint ，该变量的值就加1；计算一个lsn对应的redo日志文件组偏移量，checkpoint_lsn,checkpoint_no,checkpoint_offset这三个值写到 redo 日志文件组的管理信息中。我们说过，每一个 redo 日志文件都有 2048 个字节的管理信息，**但是上述关于checkpoint的信息只会被写到 日志文件组的第一个日志文件的管理信息中**。不过我们是存储到 checkpoint1 中还是 checkpoint2 中呢？设 计 InnoDB 的大叔规定，当 checkpoint_no 的值是偶数时，就写到 checkpoint1 中，是奇数时，就写到 checkpoint2 中。

记录完checkpoint信息之后，redo日志文件组中的各个lsn值关系如下：

<img src="./PIC/redo.png" style="zoom: 100%;" />

将脏页刷盘和执行一次checkpoint是两回事，他们是在不同的线程上面执行的，并不是有脏页刷新就要去执行一次checkpoint



### 19.7 奔溃恢复

- 确定恢复的起点：对于对应lsn小于checkpoint_lsn的redo日志来说，它们可以被覆盖，也就是说redo日志对应的脏页都已经刷新到磁盘中了。对于对应lsn不小于checkpoint_lsn的redo日志，他们对应的脏页没有被刷盘，也可能被刷盘了，因为刷盘时异步进行的。所以需要从 对应的lsn的值等于checkpoint_lsn 开始读取 redo 日志来恢复页面。

  redo 日志文件组的第一个文件的管理信息中有两个block都存储了 checkpoint_lsn 的信息，我们当然是 要选取最近发生的那次checkpoint的信息。衡量 checkpoint 发生时间早晚的信息就是所谓的 checkpoint_no ， 我们只要把 checkpoint1 和 checkpoint2 这两个block中的 checkpoint_no 值读出来比一下大小，哪个的 checkpoint_no 值更大，说明哪个block存储的就是最近的一次 checkpoint 信息。这样我们就能拿到最近发生 的 checkpoint 对应的 checkpoint_lsn 值以及它在 redo 日志文件组中的偏移量 checkpoint_offset 。

- 确定恢复的终点：普通block的 log block header 部分有一个称之为 LOG_BLOCK_HDR_DATA_LEN 的属性，该属性值记录了当前block 里使用了多少字节的空间。对于被填满的block来说，该值永远为 512 。如果该属性的值不为 512 ，那么就是它 了，它就是此次奔溃恢复中需要扫描的最后一个block。

总结：在崩溃恢复的过程中，从redo日志文件组的第一个文件管理信息中取出最近发生的那次checkpoint信息，然后从checkpoint_lsn在日志文件组对用的偏移量开始，从redo日志的lsn大于checkpoint_lsn的redo日志开始，一直扫描日志文件的block，直到某个block没被用完。在恢复的过程，可以使用space ID+page number相同的做哈希，值为redo日志，可以快速恢复。



## 20. undo日志

事务需要保证原子性，然而事务有时候会出现执行到一半的情况，因此需要把事务变成原来的样子，这个过程称为回滚，为了回滚而所记录的东西叫做撤销日志。

### 20.2 事务ID

- 只有事务对表中的数据进行修改之后，才会为这个事务分配一个唯一的事务ID；

- 事务id如何生成：事务id本质是一个数据，分配策略与之前提到的row_id类似。服务器维护一个全局变量，每当需要为某个事务分配事务id时，就会把全局变量付给它，然后自增1，每当这个全局变量的值变为256的倍数的时候，刷新到系统表空间的页号为5的页面名为MAX TRX ID的属性中。系统下一次启动，就会把这个数加载到内存且增256
- trx_id 隐藏列：聚簇索引的记录除了会保存完整的用户数据之后，还会自动添加一个名为trx_id，roll_pointer的隐藏列，如果用户没有定义主键或者不为null的unique主键，还会自动添加一个row_id的列

<img src="./PIC/记录格式.png" style="zoom: 100%;" />



### 20.3 undo日志格式

InnoDB存储引擎在进行记录的增删改的时候，会先把对应的undo日志记录下来，undo日志记录被记录到类型为FIL_PAGE_UNDO_LOG的页面中（专门的undo日志页面）。

#### 20.3.1 Insert操作对应的undo日志

<img src="./PIC/insert undo日志.png" style="zoom: 100%;" />

插入虽然会有乐观插入和悲观插入的区分，但本质还是这条记录被放到了页面中，如果回滚，就要把这个记录删掉，因此对应的undo日志只要记录这条记录的主键即可；

当我们插入一条记录的时候，实际要向聚簇索引和二级索引都插入，回滚insert的时候，只需要记录主键信息，根据主键删除聚簇索引和二级索引。

roll_pointer本质上就是一个指向记录对应undo日志的指针，如下：

<img src="./PIC/<img src="./PIC/roll pointer.png" style="zoom: 100%;" />日志.png" style="zoom: 100%;" />

#### 20.3.2 delete操作对应的undo日志

被插入到页面的记录会根据记录头信息中的next_record属性组成链表，称为正常记录链表；被删除的记录也会根据next-record属性组成一个链表，称为垃圾链表，Page Header里面有一个Page Free属性，记录了这个链表的头节点。

删除的步骤：

- 仅仅将记录deleted_flag标志位设置为1（还会修改trx_id，roll_pointer），在删除的语句所在事务提交之前，被删除的记录一直都处于这种中间状态，为MVVC服务，叫做delete mark阶段
- 当该删除语句所在的事务提交之后 (刷新到磁盘)，会有专门的线程后来真正的把记录删除掉。所谓正真的删除，就是要把记录从正常链表移除，并加入到垃圾链表，调整一些其他信息，比如页面中的用户记录数量，垃圾链表头指针等，这个操作叫做purge。被删除的链表加入到垃圾链表，实际上时加入到垃圾链表的头指针。**之后每当新插入记录时，首先判断PAGE_FREE 指向的头节点代表的已删除记录占用的存储空间是否足够容纳这条新插入的记录，如果不可以容纳，就直接向页面中申请新的空间来存储这条记录**

设计undo日志的时候，只需要对阶段一进行回滚，因此设计了一种undo日志结构：TRX_UNDO_DEL_MARK_REC。

<img src="./PIC/delete unod.png" style="zoom: 100%;" >

在对一条记录进行delete_mark操作的时候，需要把该记录的trx_id和roll_pointer隐藏列的旧值记录到对用的undo日志的trx_id

和roll_pointer中，可以通过undo日志找到上一次对于该记录改动产生的undo日志

<img src="./PIC/插入删除.png" style="zoom: 100%;" />日志.png" style="zoom: 100%;" />

执行完delete mark操作后，中间状态记录，delete mark产生的undo日志和insert产生的undo日志都串了起来

- 与插入日志比较，它还多了一个索引各列信息，如果某个列是索引列，他就应该记录在这个地方，包括该列在记录中的位置，该列的大小和值。

#### 20.3.3 update操作对应的undo日志

- 不更新主键的情况：
  - 就地更新：更新记录时，对于被更新的每个列来说，如果更新后的列和更新前的列占用的存储空间都一样大，那么就可 以进行 就地更新 ，也就是直接在原记录的基础上修改对应列的值。再次强调一边，是每个列在更新前后占 用的存储空间一样大，有任何一个被更新的列更新前比更新后占用的存储空间大，或者更新前比更新后占用 的存储空间小都不能进行 就地更新。
  - 先删除旧纪录再插入新纪录：在不更新主键的情况下，如果有任何一个被更新的列更新前和更新后占用的存储空间大小不一致，那么就需 要先把这条旧的记录从聚簇索引页面中删除掉，然后再根据更新后列的值创建一条新的记录插入到页面中。这里的删除是指真正的删除，而不是delete mark
  - 针对上述的两种情况，设计了一种TRX_UNDO_UPD_EXIST_REC日志
- 更新主键：
  - 旧纪录进行delete mark操作，之所以只进行delete mark操作，是因为别的事务也可能访问这条记录
  - 将跟新后的各列值创建一条新的记录，插入到聚簇索引里面
  - 设计了一条TRX_UNDO_UPD_EXIST_REC日志，每对一条记录的主键值进行改动，都会记录2条日志

#### 20.3.4 增删改对二级索引的影响

对于二级索引记录来说，insert和delete操作与聚簇索引中产生的影响一样，对于update来说，会有差异。

如果update操作没设计二级索引，则不要改变

如果涉及，要进行下面两个操作：

- 对旧的二级索引记录执行delete mark操作，考虑MVVC；
- 将更新后的值创建一条新的二级索引记录然后在对于的B+树重新定位插入；



### 20.4 FILE_PAGE_UNDO_LOG页面

<img src="./PIC/undo页.png" style="zoom: 100%;" >

这种页面专门用来存放undo日志，其中undo page header是其特有的，记录了undo日志的类型，可以分为两大类：

- TRX_UNDO_INSERT （使用十进制 1 表示）：Insert操作产生的日志和Update操作更新主键产生的日志
- TRX_UNDO_UPDATE （使用十进制 2 表示）：一般由delete和update不更新主键产生的日志。
- TRX_UNDO_PAGE_START ：表示在当前页面中是从什么位置开始存储 undo日志 的，或者说表示第一条 undo日 志 在本页面中的起始偏移量。
- TRX_UNDO_PAGE_FREE ：与上边的 TRX_UNDO_PAGE_START 对应，表示当前页面中存储的最后一条 undo 日志 结束时的偏移量，或者说从这个位置开始，可以继续写入新的 undo日志 。
- TRX_UNDO_PAGE_NODE ：代表一个 List Node 结构，可以用来串成链表。

### 20.5 Undo页面链表

<img src="./PIC/undo页面链表.png" style="zoom: 100%;" >

一个事务执行过程中可能产生很多undo日志，这些日志可能在一个页面放不下，需要放到多个页面，利用TRX_UNDO_PAGE_NODE属性串成一个链表，第一个叫做first undo page，包含一些管理信息，其他叫作normal undo page。一个事务执行过程中就可能需要2个 Undo页面 的 链表，一个称之为 insert undo链表 ，另一个称之为 update undo链表，设计 InnoDB 的大叔规定对普通表和临时表的记录改动时产生的 undo日志 要分别记录（我们稍后阐释为啥 这么做），所以在一个事务中最多有4个以 Undo页面 为节点组成的链表：

<img src="./PIC/4种链表.png" style="zoom: 90%;" >

不同事务id的事务写入不同链表

### 20.6 undo日志具体写入过程

#### 20.6.1 段回忆

- 段：由若干个零散页面和若干个完整的区组成；
- 一个B+树索引对应两个段，一个叶子节点段和一个非叶子节点段这样叶子节点就会尽可能放到一起，非叶子节点尽可能放到一起。每一个段对应一个INODE Entry结构，描述了段的ID、段内的各种链表基节点，零散的页面的页号。为了定位一个INODE Entry，设计了一个Segement Header结构，占用10字节。

#### 20.6.2 Undo Log Segement Header

每一个undo页面链表对应一个段，叫 Undo Log Segement ，链表中的页面都从这个段申请的。因此在第一个Undo页面设计了一个Undo Log Segement Header 部分，包含了对应段的信息。

#### 20.6.3 Undo Log Header

同一个事务向一个Undo 页面链表 写入的Undo日志是一个组。存储这些组的信息叫做Undo Log Header。所以 Undo页面链表的第一个页面在真正写入 undo日志前，其实都会被填充 Undo Page Header 、 Undo Log Segment Header 、 Undo Log Header 这3个部分。

对于没有被重用的Undo页面链表来说，链表的第一个页面first undo page 真正写入日志之前，会填充 Undo Page Header 、 Undo Log Segment Header 、 Undo Log Header 这3个部分。对于其他页面，只会填充Undo Page Header。链表的基节点存List Base Node 存放到 first undo page 的 Undo Log Segment Header 部分， List Node 信息存放到每一个 Undo页面 的 undo Page Header 部分，所以画一个 Undo页面 链表的示意图就是这样：

<img src="./PIC/undo页面链表2.png" style="zoom: 90%;" >



### 20.7 重用Undo页面

一个undo 页面链表可以被重用，满足余下两个条件：

- 该链表只包含一个undo页面。
- 该页面已经使用的空间小于3/4



### 20.8 回滚段

一个事务在执行的过程中最多可以分配4个Undo页面链表，不同事务拥有的Undo链表不同，为了管理这些链表，有一个Rollback Segement Header页面，存放了各个Undo 页面链表的first undo page的页号，成为undo slot

每个Rollback Segement Header对应一个段，叫回滚段。

- 从回滚段申请Undo页面链表：从回滚段的第一个undo slot开始
  - 如果是FILL_NULL，就在表空间新创建一个段（UNDO LOG SEGMENT），然后从段中申请一个页面作为Undo 页面链表的first undo page，最后把该undo slot的值设置为此页面的地址，代表以及分配
  - 如果不是FILL_NULL，说明该undo slot已经指向一个链表。也就是说这个undo slot已经被别的事务占用了，需要跳到下一个undo slot 重复上述步骤。一个回滚段最多包含1024个undo slot。
- 多个回滚段：系统表空间5号页面的某个区域包含了128个8字节的各自，指向128个回滚段页面。
- 回滚段的分类：
  - 0号，33-127号回滚段属于一类，为普通表的改动分配undo页面链表
  - 1-32号属于一类，为临时表记录改动分配undo页面链表
- roll_pointer：本质是一个指针，指向一条undo日志的地址

**为事务分配undo页面链表的详细过程：**

- 事务在执行过程中，对普通表记录进行首次改动之前，首先会到系统表空间5号页面分配一个回滚段，即获取一个Rollback Segement Header地址。一旦某个回滚段被分配给了这个事务，那么之后该事务再对普通表进行改动，就不会在分配了；
- 在分配到回滚段后，首先看一下这个回滚段的两个 cached链表 有没有已经缓存了的 undo slot ，比如如果事务做的是 INSERT 操作，就去回滚段对应的 insert undo cached链表 中看看有没有缓存的 undo slot ； 如果事务做的是 DELETE 操作，就去回滚段对应的 update undo cached链表 中看看有没有缓存的 undo slot 。如果有缓存的 undo slot ，那么就把这个缓存的 undo slot 分配给该事务。
- 如果没有缓存的 undo slot 可供分配，那么就要到 Rollback Segment Header 页面中找一个可用的 undo slot 分配给当前事务。
- 找到可以undo slot后，如果该undo slot是从如果该 undo slot 是从 cached链表 中获取的，那么它对应的 Undo Log Segment 已经分配了，否则的话需要在表空间创建一个 Undo Log Segment ，然后从该 Undo Log Segment 中申请 一个页面作为 Undo页面 链表的 first undo page 。 然后事务就可以把 undo日志 写入到上边申请的 Undo页面 链表了！

- 如果一个事务在执行过程中 既对普通表的记录做了改动，又对临时表的记录做了改动，那么需要为这个记录分配2个回滚段。并发执行的不同事务其实也可以被分配相同的回滚段，只要分配不同的undo slot就可以了。



### 20.9 undo日志在奔溃回复时的作用

为了保证事务的原子性，需要在服务器重启的时候把未提交的事务回滚掉，这些工作落在了undo日志头上。

- 我们可以通过系统表空间的第五号页面定位到128个回滚段的位置，在每个回滚段的1024个undo slot中找到那些值不为FILL_NULL的undo slot，每一个undo slot对应一个undo 页面链表。然后从undo页面链表第一个undo log segement header找到TRX_UNDO_STATES属性，得到该页面链表所处状态。如果为active，则意味着有一个活跃的事务正向这个undo页面链表写入日志。然后再在undo log segement header找到TRX_UNDO_LAST_LOG属性，通过该属性找到本undo页面链表最后一个Undo Log Header 的位置。从该Undo Log Header中可以找到事务id和一些其他信息，该事务id对应的事务就是未提交的事务。通过undo日志记录的信息将该事务对页面所作的操作的全部回滚。



## 21. 事务的隔离级别和MVVC

每个客户端和服务器建立连接后，就形成了一个会话。

### 21.1 事务并发执行的一些一致性问题

- 脏写：如果一个事务修改了另一个未提交事务修改过的数据，就意味着发生了脏写现象；
- 脏读：如果一个事务读到了另外一个事务未提交的修改过的数据，就意味着发生了脏读的现象；严格解释：T1先修改了数据x的值，然后T2又读取了未提交事务T1针对x修改后的值，之后T1终止而T2提交，这意味着T2读取到了一个根本不存在的值，这也就是脏读现象。
- 不可重复读：如果一个事务修改了另外一个未提交事务读取的数据，就发生了不可重复读的现象。严格解释：T1先读取了数据x的值，然后T2又修改了未提交事务T1读取的数据x的值，之后T2提交，然后T1再读取x的值就会得到与第一次读取时候不同的值。
- 幻读：如果一个事务现根据某些搜索条件查询出一些记录，在该事务未提交的时候，另一个事务写入了一些符合条件的记录，就意味发生了幻读的现象，也就是后续读取到了之前没有的记录。

### 21.2 SQL的四种隔离级别

- 未提交读
- 已提交读
- 可重复读
- 可串行化

SQL规定，不同的隔离界别，并发事务执行过程中可以发生不同的现象

| 隔离级别 | 脏读   | 不可重复读 | 幻读   |
| -------- | ------ | ---------- | ------ |
| 未提交读 | 可能   | 可能       | 可能   |
| 已提交读 | 不可能 | 可能       | 可能   |
| 可重复读 | 不可能 | 不可能     | 可能   |
| 可串行化 | 不可能 | 不可能     | 不可能 |

也就是说：

- READ UNCOMMITTED 隔离级别下，可能发生 脏读 、 不可重复读 和 幻读 问题。 
- READ COMMITTED 隔离级别下，可能发生 不可重复读 和 幻读 问题，但是不可以发生 脏读 问题。 
- REPEATABLE READ 隔离级别下，可能发生 幻读 问题，但是不可以发生 脏读 和 不可重复读 的问题。
-  SERIALIZABLE 隔离级别下，各种问题都不可以发生。

MySQL支持的四种隔离级别，支持上述四种，默认隔离级别为可重复读，可以很大程度禁止幻读的发生



### 21.3 MVVC原理

#### 21.3.1 版本链

聚簇索引记录都包含下面两个必要的隐藏列：

trx_id：一个事务每次对某条聚簇索引记录进行改动的时候，都会把事务的事务id赋给这个列；

roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧版写入undo日志中，相当于一个指针，可以通过它找到记录修改前的信息。

<img src="./PIC/MVVC.png" style="zoom: 90%;" >

每对记录进行一次改动，都会记录一条undo日志，每条undo日志都会有一个roll_pointer属性（insert除外，因为insert操作的记录没有更早的版本），通过这些属性将undo日志串成一个链表。链表的头节点就是当前记录最新的值，每个版本都包含该版本的对应的事务id，利用这个记录的版本连来控制并发事务访问相同记录的行为，叫做MVVC。

InnoDB采用锁来保证不会出现脏写现象。

实际上insert undo只在事务回滚时起作用，当事务提交后，该类型的undo日志就没用了，它占用的Und o Log Segment也会被系统回收（也就是该undo日志占用的Undo页面链表要么被重用，要么被释放）。 虽然真正的insert undo日志占用的存储空间被释放了，但是roll_pointer的值并不会被清除。



#### 21.3.2 ReadView

对于使用未提交读的隔离级别的事务，可以读到未提交事务修改的记录，所以直接读取最新版本。对于使用串行化的隔离级别的事务，使用加锁的 方法来访问记录。

对于已提交读和可重复读，都必须保证读到已经提交的事务修改过的记录，也就是说假如另一个事务已经修改了记录但是尚未提交， 是不能直接读取最新版本的记录的，核心问题就是：需要判断一下版本链中的哪个版本是当前事务可见的。

因此，提出了一个 ReadView 的概念，这个 ReadView 中主要包含4个比较重要的内容：

- m_ids：生成read_vie的时候，当前系统中活跃的读写事务的事务id列表。
- min_trx_id：生成readview时，当前系统活跃的最小的事务id，也就是上一个的最小值；
- max_trx_id：生成readview时，系统应该分配给下一个事务的事务id
- creator_trx_id：生成该readview的事务的事务id，初始是0，只有改变表才会赋值

因此有了readview后，在访问某条记录的时候，需要按照下面的步骤来判断某个记录的某个版本是否可见：

- 如果被访问版本的trx_id属性与readview中的creator_id相同，意味着当前事务在访问他自己的修改过的记录，所以该版本可以被当前事务访问。
- 如果被访问的版本的trx_id属性值小于readview的min_trx_id，表明生成该版本的事务在当前事务生成readview前已经提交，所以该版本可以被当前事务访问。
- 如果被访问的版本trx_id属性值大于或等于readview中max_trx_id，表明生成该版本的事务在当前事务生成readview之后才开启，所以该版本不能被当前事务访问；
- 如果被访问版本的 trx_id 属性值在 ReadView 的 min_trx_id 和 max_trx_id 之间，那就需要判断一下 trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该 版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问。
- **在MySQL中，已提交读和可重复度的隔离级别与一个非常大的区别就是他们生成的 readview的时机不同，已提交读是每次读取数据前都生成一个readview；可重复读这一隔离级级别，只会在第一次执行查询语句生成一个readview，之后查询就不会生成readview了**

#### 21.3.3 二级索引与MVVC

只有聚簇索引记录中才有trx_id和roll_pointer隐藏列，如果查询是用二级索引来执行查询，如何判断其可见性？大致分为两步：

- 二级索引页面的page header有一个PAGE_MAX_TRX_ID属性，每当对该页面中的执行记录执行增删改操作，如果执行该操作的事务的事务id大于这个属性值，就会更新。这也就意味着 PAGE_MAX_TRX_ID代表着修改该二级索引页面的最大事务id，若生成readview的min_trx_id是否大于该页面的这一属性，如果大于，则该页面的记录都对该readview可见。
- 否则，利用主键执行回表操作，得聚簇索引记录，执行之前的操作。



**所谓的 MVCC （Multi-Version Concurrency Control ，多版本并发控制）指的就 是在使用 READ COMMITTD 、 REPEATABLE READ 这两种隔离级别的事务在执行普通的 SEELCT 操作时访问记录的版 本链的过程，这样子可以使不同事务的 读-写 、 写-读 操作并发执行，从而提升系统性能。 READ COMMITTD 、 REPEATABLE READ 这两个隔离级别的一个很大不同就是：生成ReadView的时机不同，READ COMMITTD在每一 次进行普通SELECT操作前都会生成一个ReadView，而REPEATABLE READ只在第一次进行普通SELECT操作 前生成一个ReadView，之后的查询操作都重复使用这个ReadView就好了。**



### 21.4 purge

- insert undo日志在提交之后，就可以释放了（因为insert是一个从0到1的过程）；而update undo日志由于还要支持MVVC，因此不能删掉
- 为了支持 MVCC ，对于 delete mark 操作来说，仅仅是在记录上打一个删除标记，并没有真正将它删除掉。



一个事务写的一组undo日志中都有一个undo log header部分，这部分有一个TRX_UNDO_HISTORY_NODE属性，表示为一个名为history的链表节点，当一个事务提交的时候，就会把这个事务产生的一组update undo 日志插入history链表的头部

每个回滚段，都有一个名为rollback segement header的页面，有两个属性，表示history链表的基节点以及hsitory链表占用页面的数量。也就是说一个事务在某个回滚段写入一组update undo 日志在事务提交之后，就会加入到这个回滚段的history链表中

我们应该在合适的时候把update undo日志和被标记为删除的记录彻底删掉，这个操作就叫purge。

update undo日志和被标记为删除的记录只是为了mvvc而存在的，只要系统最早产生的readview不再访问，那就可以删除了，因此：

- 在一个事务提交的时候，会为这个事务生成一个名为事务no的值，用来表示事务提交的顺序，先提交的事务no小，后提交的no大。
- 一组undo日志对应的undo log header中有一个属性记录该事务no，事务提交的时候，会把事务no填入这个属性。而history链表又是按照事务提交的顺序来排序的。
- 一个readview结构除了包括之前唠嗑的几个属性，还包括一个事务no的属性，生成一个readview会把比当前系统最大的事务no+1赋值给这个属性。
- 因此，InnoDB把当前系统所有的readview按照时间串成一个链表。当执行pure操作的时候，把系统最早生成的readview取出来，然后从history链表取出事务no较小的undo日志，如果一组undo日志的事务no小于当前系统最早生成的readview的事务no，那么就证明该undo日志没有用了，就可以从history链表移除。如果该undo日志包含delete marrk产生的操作，也需要把该这个中间记录删除。

随着系统的运行，在确定系统中包含最早产生的那个 ReadView 的事务不会再访问某些 update undo日志 以及被打了删除标记的记录后，有一个后台运行的 purge线程会把它们真正的删除掉



## 22. 锁（具体见书）

### 22.1 解决并发事务带来的问题两种基本方式

- 写-写情况：通过加锁来执行。多个未提交的事务对一条记录进行改动，需要让他们排队执行，这个排队的过程就是通过加锁来执行的，锁本质上是内存中的一个数据结构。
- 读-写或者写-读情况：
  - 方案一，读操作是用MVVC，写操作进行加锁；
  - 方案二：读写都是用加锁的情况。
- 事务利用MVVC进行读取操作一般称为一致性读。

#### 22.1.1 锁定读

- 共享锁和独占锁

  - 共享锁：简称s锁，事务要读取一条记录时，需要先获取该记录的S锁；
  - 独占锁：也成为X锁，事务需要改动一条记录的时候，需要先获取记录的X锁。
  - S锁和S锁兼容，X锁和S锁和X锁都不兼容。
  - 在读取记录前加锁的读取操作称为锁定读

  MySQL提供下面两种语法进行锁定读：

  - select  ... lock in share mode 语句为读取记录加S锁
  - select ... for update  语句为读取记录加X锁

  insert语句一般不需要再内存中生成锁结构，并单纯考隐式锁保护插入记录，update和delete语句在执行过程中，在B+树定位到待改动的记录并给记录加锁的过程也是一个锁定读。

  IS意向共享锁，IX意向独占锁时表级锁，它们的提出仅仅时为了在之后加表级别的S锁和X锁时，可

  以判断表中的记录hi发被上锁，避免了遍历。因为要确保表记录没有X锁，也就是表没有表级别的IX锁，才可以给整个表加S锁。要想给表加上X锁，那么要确保表里面的记录没有X锁和S锁，也就是表没有表级别的IS和IX锁。

- InnoDB中的行级锁有下面这几种：
  - record lock：正经记录锁，只对记录本身加锁
  - Gap lock：锁住记录的间隙，以防止别的事务向间隙插入新纪录
  - next-key lock：record lock和gap lock的组合，即保护好记录本身，也防止别的记录往间隙插入。
  - insert intention lock：很鸡肋锁，仅仅是为了解决"在当前事务插入记录时因碰到别的事务加的gap锁而进入等待状态而生成一个锁结构而提出的"。某个事务获取一条记录的该类型的锁之后，不会阻止别的事务继续获取该记录而上任何类型的锁
  - 隐式锁：依靠记录的trx_id属性来保护就记录不被别的事务而改动该记录
- InnoDB存储引擎的锁都在内存中对应着一个锁结构，有时候为了节省锁结构，会把符合下面条件的锁放到一个锁结构当中：
  - 在同一个事物中进行加锁操作
  - 被枷锁的记录在同一个页面
  - 加锁的类型是一样的
  - 等待的状态是一样的
- 不同的事务由于持有对方需要的锁而导致事务无法进行的情况称为死锁，死锁发生的时候，InnoDB回选择一个较小的事务进行回滚。